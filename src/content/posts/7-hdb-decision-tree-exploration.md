---
title: "Decision trees and random forests: HDB Resale Price Predictor"
description: "Exploring HDB Resale Prices using decision trees and random forests"
date: 2023-05-25T12:00:00Z
image: "/images/posts/07.jpg"
categories: ["learning", "hdb prices"]
authors: ["Kelvin Soh"]
tags: ["decision tree", "random forest", "sklearn", "feature importance"]
draft: false
---

The concept of the decision trees and random forests sound so simple once
you hear about them it makes me wonder why I haven't heard of them (vs the
ubiquitous linear regression). Compared to the other attempts so far
it has been a joy to implement
and analyze the results by using the techniques on the HDB resale price data set.

## A simple tree

We first construct a simple tree with only 8 leaves. We also just use the simpler data
columns: the year the flat was built, the floor area and floor level of the flat and the
date of the resale transaction.

![hdb decision tree](/images/posts/decision_tree.svg)

Translating the results, the tree placed our 307 data points into 8 categories,
with the average resale price in descending order listed below:

1. Built after 2015 and above 9th floor: 27 houses averaging ~$450,000
2. Built after 2015 and below 9th floor: 62 houses averaging ~$420,000
3. Built between 2005 and 2015 and above 9th floor: 31 houses averaging ~$420,000
4. Built between 2005 and 2015 and below 9th floor: 17 houses averaging ~$390,000
5. Built between 1985 and 2005, at least 68 sqm and sold after November 2022: 35 houses averaging ~$380,000
6. Built between 1985 and 2005, at least 68 sqm and sold before November 2022: 33 houses averaging ~$350,000
7. Built before 1985 and at least 68 sqm: 36 houses averaging ~$330,000
8. Built before 2005 and less than 68 sqm: 66 houses averaging ~$300,000

The fact that houses built recently, at a higher floor, with a bigger area and sold more recently goes for higher
prices isn't too shocking, but I liked how we were able to get a sense of which feature contributed to the price the most,
and put a number on a good boundary to consider classifying the data points.

## Feature importance

The following is a feature importance chart of the above analysis (this time using more than 8 leaves).

![hdb feature importance](/images/posts/feature_importance.png)

Unsurprisingly the year the flat was built is the biggest predictor (since we have restricted our data set to 3 room flats of similar floor area.)
Interestingly, however, was the finding the date of transaction isn't as important. The price has definitely been increasing with time (and I did
do further analysis on it upon discovering this finding to validate that), but our data seems to suggest that other factors still play a much bigger role
in the final predicted price.

It remains to be seen if this trend will hold once I incorporate more data (more than just 3 room flats in the woodlands region), but if that is so
it may actually be a good thing. I had planned to translate my findings into a simple web app to predict the resale price, which is useful if a flat
someone is considering to buy doesn't have an exact match from recent past records (eg different floors and different blocks). If the transaction date
is a significant feature, then to predict the current or future resale price we will likely predict a higher price than historically (given the recent trend),
which may unwittingly lead to influencing future prices if the app ever gains traction.

## Random forests and prediction metrics

Previously using linear regression we were able to get our root mean square error to be in the range of
~19,000 if we split the data set up to use the most recent
transactions as the validation set.

With the binary tree approach, I obtained rmse in the range of ~21,000, a roughly 10% worse performance.
Using random forests lowered the rmse to the range of ~19,000 which is similar to the linear regression baseline.

Adding more data in the form of map latitude and longitude coordinates didn't improve the results unfortunately.
It is something I'm looking to explore more in depth with neural nets in the next post.

## Concluding thoughts

While it hasn't beat the simple linear regression baseline (maybe gradient boosted trees can?), I did learn quite a bit
about my data, and it's not a stretch to think that the area, floor and years are quite linearly correlated to the
price.

For other data sets I'd definitely be eager to use this method (and explore gradient boosted trees), but
for my further exploration with this particular data set
I will likely continue using linear regression as the baseline.

## The cover image

Generated by [Stable Diffusion Online](https://stablediffusionweb.com/).
I used the following prompts, and got something I like at the
1st
attempt!

1. HDB flats inside a forest
